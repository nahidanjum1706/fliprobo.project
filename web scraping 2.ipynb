{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the url of the webpage\n",
    "url=\"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create 4 empty lists\n",
    "Jobs_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for page in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        Jobs_Title.append(i.text)\n",
    "\n",
    "#Job_Location of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        Job_Location.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        Company_Name.append(k.text)\n",
    "\n",
    "#Experience_Required of first 10 jobs data on the website\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        Experience_Required.append(l.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jobs_Title of first 10 jobs       \n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "\n",
    "#Job_Location of first 10 jobs\n",
    "Job_Location=Job_Location[0:10]\n",
    "\n",
    "#Company_Name of first 10 jobs\n",
    "Company_Name=Company_Name[0:10]\n",
    "\n",
    "#Experience_Required of first 10 jobs\n",
    "Experience_Required=Experience_Required[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Jobs_Title : 10\n",
      "Lenght of Job_Location : 10\n",
      "Lenght of Company_Name : 10\n",
      "Lenght of Experience_Required : 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the lists\n",
    "print('Lenght of Jobs_Title :', len(Jobs_Title)), print('Lenght of Job_Location :', len(Job_Location)),\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Experience_Required :', len(Experience_Required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - SAP</td>\n",
       "      <td>Pune, Delhi, Bengaluru, Gurgaon</td>\n",
       "      <td>Boston Scientific Corporation</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Security Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst -Azure Data lake, Azure Data factory</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business / Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Intern Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Outsource Big Data</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NiFi Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...   \n",
       "1                                 Data Analyst - SAP   \n",
       "2                   Hiring Data Analysts on Contract   \n",
       "3                                Senior Data Analyst   \n",
       "4                              Security Data Analyst   \n",
       "5  Data Analyst -Azure Data lake, Azure Data factory   \n",
       "6                            Business / Data Analyst   \n",
       "7                     Data Analyst - O2C - Bangalore   \n",
       "8                                Intern Data Analyst   \n",
       "9                                  NiFi Data Analyst   \n",
       "\n",
       "                          Job Location  \\\n",
       "0                            Bengaluru   \n",
       "1      Pune, Delhi, Bengaluru, Gurgaon   \n",
       "2                            Bengaluru   \n",
       "3                Bengaluru / Bangalore   \n",
       "4                            Bengaluru   \n",
       "5  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "6                            Bengaluru   \n",
       "7                            Bengaluru   \n",
       "8                            Bengaluru   \n",
       "9                            Bengaluru   \n",
       "\n",
       "                                  Company Name Experience Required  \n",
       "0            Flipkart Internet Private Limited             1-4 Yrs  \n",
       "1                Boston Scientific Corporation             3-5 Yrs  \n",
       "2            Flipkart Internet Private Limited             2-5 Yrs  \n",
       "3                           Schneider Electric             2-5 Yrs  \n",
       "4                        Philips India Limited             2-4 Yrs  \n",
       "5                             Mindtree Limited             5-9 Yrs  \n",
       "6                       IBM India Pvt. Limited             2-4 Yrs  \n",
       "7                       RANDSTAD INDIA PVT LTD             2-4 Yrs  \n",
       "8                           Outsource Big Data             0-1 Yrs  \n",
       "9  Capgemini Technology Services India Limited             4-6 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Data_Analyst=pd.DataFrame({})\n",
    "Data_Analyst['Job Title']=Jobs_Title\n",
    "Data_Analyst['Job Location']=Job_Location\n",
    "Data_Analyst['Company Name']=Company_Name\n",
    "Data_Analyst['Experience Required']=Experience_Required\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the url of the webpage\n",
    "url=\"https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Jobs_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Job_Description=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for page in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        Jobs_Title.append(i.text)\n",
    "\n",
    "#Job_Location of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        Job_Location.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        Company_Name.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Data Mining/ Machine Learning/ Statistical Analysis\\n\\nRequirements :\\n\\n- 3-9 years of strong experience in data mining, machine learning, and statistical analysis.\\n\\n- BS/MS/Ph.D. in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Matlab, Python, etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " 'Roles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " \"Job Description :\\n- We are looking for a researcher who specializes in building personalization/recommender systems algorithm (ML APIs) for the applications mentioned above and work with our engineers to deploy them as scale.\\nWhat you will do :\\n- Apply your research expertise to build our ML-driven recommender system products, help us develop new solutions and unlock new directions, as well as analyse and optimise the systems we already. \\n- You'll work closely with product teams and mentor them on best practices for modern ML, and keep the wider team informed on the state-of-the-art. In addition, you will be in a strategic position to influence future roadmaps for recommender system products.\\n- Collaborate with a cross-functional agile team spanning user research, design, data science, product management, and engineering to build new product features that advance our mission to connect artists and fans in personalized and relevant ways.\\n- Prototype new approaches and production-ize solutions at scale for our hundreds of thousands of active users. Help drive optimization, testing, and tools to improve quality.\\nRequirements :\\n- Master, Post-graduate or Ph.D. in computer science, machine learning, information retrieval, recommendation systems, natural language processing, statistics, math, engineering, operations research, or another quantitative discipline; or equivalent work experience.\\n- Good theoretical grounding in core machine learning concepts and techniques.\\n- Ability to perform comprehensive literature reviews and provide critical feedback on state-of-the-art solutions and how they may fit different operating constraints.\\n- Experience with a number of ML techniques and frameworks, e.g. Natural Language Processing, Recommender Systems, sampling, linear regression, decision trees, SVMs, deep neural networks, etc.\\n- Familiarity with one or more Deep learning software frameworks such as Tensorflow, PyTorch.\",\n",
       " 'Working experience in Artificial Intelligence, Python, R, Machine Learning\\nExperience in data mining, Strong math skills (e.g. statistics, algebra)\\nStrong programming skills in: R, Python and familiarity with Java, Scala, C - DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift\\nExperience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20\\nStrong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc)\\nExperience with Deep Learning tools Tensorflow, Theano, Caffe etc. - Elastic Search, NLP background and Machine Learning Platforms\\nExperienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)\\nExperience in neural networks, regression, classification and clustering\\nDeep industry knowledge on any of the following: Banking, Insurance, Retail Manufacturing\\nDeep understanding of Statistical algorithms: Linear and Non-Linear models, classification problem, optimization techniques, Market mix models, A/B Testing and campaign management, Feature ranking/selection techniques, supervised/unsupervised learning, Collaborative filtering, Apriori Market Basket analysis, SVM, Gradient boosting, Survival analysis etc.\\nTo help designing, innovating and building our next generation ML architecture\\nFull time programming experience within an operation or technical department.\\nIdentify valuable data sources and automate collection processes\\nUndertake pre-processing of structured and unstructured data\\nAnalyze large amounts of information to discover trends and patterns\\nBuild predictive models and machine-learning algorithms\\nCombine models through ensemble modelling\\nPresent information using data visualization techniques\\nPropose solutions and strategies to business challenges\\nCollaborate with engineering and product development teams\\nMentor others in the use of AI/Machine Learning',\n",
       " 'Key Responsibilities\\nBe responsible for scaling our analytics capability across all internal disciplines and guide our strategic direction in regards to analytics\\nOrganize and analyze large, diverse data sets across multiple platforms\\nIdentify key insights and leverage them to inform and influence product strategy\\nTechnical Interactions with vendor or partners in technical capacity for scope/ approach & deliverable.\\nDevelops proof of concept to prove or disprove validity of concept\\nWorking with all parts of the business to identify analytical requirements and formalize an approach for reliable, relevant, accurate, efficient reporting on those requirements\\nDesigning and implementing advanced statistical testing for customized problem solving\\nDeliver concise verbal and written explanations of analyses to senior management that elevate findings into strategic recommendations.\\n\\nDesired Candidate Profile\\n\\nQualifications:MTech / BE / BTech / MSc in CS or Stats or Maths, Operation Research, Statistics, Econometrics or in any quantitative fieldExperience:3+ Years experience in analytical domain\\n\\nFunctional Competencies:\\nExcellent analytics, logical, problem solving and numerical skills\\nExperience in using Python\\nExperience in working with large data sets and big data systems (SQL, Hadoop, Hive, etc.)\\nKeen aptitude for large-scale data analysis with a passion for identifying key insights from data\\nExpert working knowledge in various machine learning algorithms such XGBoost, SVM Etc.,\\nExpertise in Data Mining, Statistical Analysis, Regression, Logistics Regression, Segmentation, Time Series Forecasting, Market Basket Analysis, Decision Tree, CHAID, Test Mining, Hypothesis Testing, A/B Testing and Modeling\\nPreferable to have\\nExperience in Credit risk analytics, Fraud analytics\\nExperience in Collections analytics, NPA\\nAnalytical experience in Vehicle lending business (Two wheeler, Tractor, Car, Commercial) and unsecured loans.\\nCustomer Acquisition',\n",
       " 'Roles and Responsibilities\\nSkill : NLP,Semantic model, NER model, Deep Learning\\n\\nNotice : who can join in a month max\\n\\nJob description :\\n\\n- 5+ years of experience using analytical toolslanguages like Python & R on large scale data\\n\\n- Must have Semantic model & NER experience\\n\\n- Experience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\\n\\n- Experience on Deep Learning for Image processing, Video analytics will be a plus\\n\\n- Must have strong experience in NLPNLGNLU applications using any popular Deep learning frameworks like Open CV, PyTorch, Theano, Tensor Flow, Caffe. Should have implemented solutions for industry use cases.\\n\\n- Demonstrated ability to engage with client stakeholders at multiple levels and provide consultative solutioning across different domains\\n\\n- Deep knowledge of techniques such as Linear Regression, gradient descent, Logistic Regression, Forecasting, Cluster analysis, Decision trees, Linear Optimization, Text Mining etc.\\n\\n- Must have experience in doing POCs\\n\\n- Strong applied fundamentals in data management, parallel computing and distributed systems; experience in productionizing & retraining models\\n\\n- Ability to guide and mentor teams of associates on solution development and approaches\\n\\n- Broad knowledge of fundamentals and state-of-the-art in NLP and machine learning\\n\\n- Coding skills in one or more programming languages such as Python, Scala, Java, C, C++\\n\\n- Expert high level of understanding on language semantic concepts & data standardization\\n\\n- Proven track record of successful models and practical implementation\\n\\n- Hands-on experience with popular ML frameworks such as TensorFlow\\n\\n- Experience with application development practices at scale, from problem definition to deployment.\\n\\n- Familiarity with Cloud services such as AWS, SageMaker etc. is considered a plus\\n\\n- Develop and apply Statistical Modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications\\n\\n- Knowledge in Machine Learning techniques in entity resolution, common speech products or text search domain',\n",
       " 'Roles and Responsibilities\\n\\nMust have strong Python Programming Skills\\nStrong analytical & algorithm development skills\\nLogical and Analytical skills must be really strong\\nMust have worked in DeepLearning Efforts - Especially computer vision.\\nMust have experinece with Object Detection - Custom model training for Object detection\\nShould have experience with atleast one or more of these - Tensorflow, Keras, PyTorch\\n\\nPrimary Skills - Python + tensorflow - Keras / PyTorch, OpenCV\\nPerks and Benefits\\n\\nKindly share your resume to kandavelkumar.lakshmanan @cesltd.com',\n",
       " \"We are hiring Data Scientist and Senior Data Scientist Academic Operations for our leading EdTech Client.\\n\\nCall/WhatsApp- Amit-9379292728\\nEmail: amitkumar.s@randstad.in\\n\\nor Fill the google form - https://tinyurl.com/JobAppForm4\\n\\nJob Responsibilities:\\nYour primary job responsibility will include (and not limited to):\\nOwn the student's learning outcomes by providing them with support on the topics covered in the\\ncurriculum.\\nInvolve in the residency class room sessions to facilitate lectures and lab sessions\\nBe the first point contact for participants for academic queries and manage discussion\\ngroups\\nMonitor participants academic performance and make learning interventions in the\\nform of remedial sessions, coaching and mentoring\\n\\nCoordinate with faculty to create best in class learning material - video, reading material,\\nassignments, exams\\nDesign and conduct examinations to measure the learning outcome of participants\\nIdentify & Solve interesting problems involving rich datasets in various domains.\\nAccordingly, create capstone projects on the evolving use cases in the industry\\nIdentify key emerging trends in the industry and maintain a rich reference material\\nAssist program director and senior operations and academics managers in planning\\non-campus sessions, preparing schedules, evaluation and grading\\nIdentify key reporting metric sand create dashboards to enable quick decision making\\nAutomation of manual data collection, data cleansing and exploratory data analysis\\nCreate and maintain business and technical requirements\\nIdentify technical solutions and perform feasibility analysis\\nCreate technical roadmaps for the operations Team\\nManage, identify and suggest processes for smoother program management to\\nensure a consistent and trouble free learning experience\\nCoordinate with IT and Admin to ensure smooth execution at various locations\\nTravel to other cities if required to manage residencies\\n\\nRelevant Background:\\nGraduate with an exceptional academic track record\\nCompetency: (Top 3)\\n1. Passion for learning and having great learning outcomes\\n2. Ability to multitask and coordinate with multiple stakeholders\\n3. Excellent knowledge in python, tableau and ML concepts\",\n",
       " 'Role Description:\\nA Sr. Data Scientist who lead the development of analytics / machine learning / AI models for generating future prediction using data.\\nResponsibilities : - Understanding the project requirement\\n- Understand if there is any already existing ML model\\n- Leading analytics project & provide necessary guidance to the team\\n- Understand the data & doing EDA\\n- Feature engineering - Building Data Science models\\n- Validate & Piloting ML models\\n- Model tuning & improvement\\nRequired Skills:\\n- Sound theoretical knowledge in ML algorithm and their application\\n- Strong fundamental on statistics\\n- Experience in leading multiple data science projects\\n- Hands on experience on Machine learning / data science\\n- Strong stakeholder management skills\\n- Expert in Python - Hand on experience in SPARK Scala or PySpark\\nAdded Advantage:\\n- Hands on experience in Azure data bricks\\n- Working experience in CPG domain\\nSkills Required:\\nDATA ANALYSIS, Machine learning, Python, Databricks',\n",
       " 'DATA SCIENTIST / MACHINE LEARNING EXPERT\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nExcellent understanding of Machine learning techniques and algorithms\\nETL Knowledge (data cleansing)\\nData Visualization\\nExpereience in BI poject\\nExperience in Agile/ SCRUM projects\\nExperience in supply chain is an added advantage\\nKey Technical Requirements\\nR / Mathlab / Octave\\nNoSQL database such as MongoDB, DocumentDB, CosmosDB, etc\\nGit\\nJavaScript, Angular 2/4, Node JS\\nAzure and AWS',\n",
       " 'Roles and Responsibilities\\n- Machine Learning techniques (recommendation engines, ensemble models such as random forests, bagging and boosting, support vector machines, dynamic optimization etc.)\\n\\n- Design and build systems that mine massive datasets and structure/ engineer it to be usable for machine learning models\\n\\n- Explore and suggest AI based solutions such as Convolutional Neural Networks\\n\\nWe are looking for talented individuals to join our team - people with an empiricist attitude towards data, with mathematical intuition, curiosity, a positive outlook and who have worked on real data problems.\\n\\n- 2+ yrs of experience as Data Scientist\\n\\n- Strong programming skills with at least one scripting language (e.g. R, Python). Conversant with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.\\n\\n- Should have at-least 1 end-to-end ML project experience. Starting from organizing and munging data, prototyping algorithms in scripting languages to deploying a solution in a stable platform\\n\\n- Experience in working with packages such as - Generalized linear models (Lasso, Ridge, Logit), Recommendation engines (SVD, ALS, Boltzmann machine in platforms such as Mahout), Neural Networks (nnets, tensorflow),Optimization (heuristic models), Visualization techniques (t-sne, ggplot, matplotlib, shiny, D3js).\\n\\n- Exposure to massive data storage architectures - Map-Reduce/ Columnar Databases/ NoSQL/ RDD-Spark',\n",
       " 'Mailkit is an European Marketing Automation company in search of a Data Scientist with knowledge in Python and Machine Learning to join our R&D team. Applicants should have knowledge of algorithms, statistical analysis, data mining / text mining with / NLP / NLTK , Text analytics, etc.\\n\\nKeeping in mind the current pandemic threat, we are offering remote job facility as well, that means selected candidate can work from his/her home comfort. But preference will be given to candidates who are willing to work from our office location in Kolkata. He or She should have minimum 3 years of experience in the said technology. Interested candidates should be able to present a good project portfolio. Developer(s) should be able to tactfully resolve complex issues and implement new things by himself or herself. Applicants should be able to speak and write good English.\\n\\nRoles and Responsibilities\\nKnowledge in deep learning algorithms and AI system design and architecture.\\nExcellent understanding of complex system architecture, components and requirements\\nInnovative and creative, logical thinker,.\\nAdvanced level proficiency in Python programming\\nBe able to read, write and speak good English\\n\\nResponsibilities\\nResponsible for machine learning technology and application analysis, understand the latest industrial and academic developments in AI/ML\\nStudy and innovate in Deep Learning/machine learning and its application in diverse domains\\nDesign competitive AI/ML services and user experience.\\nWork with the team to integrate these algorithms into larger solutions.\\nPerks and Benefits\\nCandidates might get the opportunity to work from home.\\nSaturdays and Sundays, fixed weekend offs.\\nemployees get 6 sick leaves, 18 casual leaves and 14 calendar holidays every year.\\non time salary, usually last working day of every month.',\n",
       " 'Introduction\\nThe Data Scientist actively participates on multi-functional project teams developing analytics enabled solutions, owning and leading the work done. Recommends and implements analytics enabled solutions to improve business process, to generate insights, to support business goals and strategy development. They would also own and deliver complete projects of moderate scope\\n\\n\\nYour Role and Responsibilities\\nAs a Data Scientist, you recommend and implements analytics enabled solutions to improve business process, to generate insights, to support business goals and strategy development\\nRecommends and implements analytics enabled solutions to improve business process, to generate insights, support business goals and strategy development\\nExplore and validate client data for the specific Analytics requirements.\\nAnalyze client data of noisy, missing data or incomplete data.\\nWrite ETL modules to ingest client data into the Analytics DB.\\nDesign test cases for the Analytics modules.\\nDevelop Analytics modules, for the specific client implementation.\\nImplement changes or new components into the Analytics modules.\\nProduction integration and end to end testing.\\n\\n\\nRequired Technical and Professional Expertise\\nMinimum 6-8 years of experience in programming, statistics, machine learning, data visualization, exploratory data analysis, model production, insight generation and data wrangling\\nMasters Degree in Computer Science, Statistics, Applied Math or meaningful field\\nExperience building AI models (ML, NLP, Neural Networks)\\nExperience in using containerized workloads and services such as Kubernetes, Docker, etc.\\nExperience in Cloud Architecture (AWS, Azure, IBM)\\nExpertise with R, SQL and Python; familiarity with Scala, Java or C# is an asset\\nAgent based modeling and simulation & conversational skills for ChatBots\\nKnowledge of Agent Development Frameworks (e.g. SPADE, JADE, etc), Knowledge Graphs and Ontologies.\\n\\n\\n\\nPreferred Technical and Professional Expertise\\nAbility to take care of highly personal and confidential information\\nExperience in understanding and executing business controls\\nProven analytical and problem solving skills\\nAmbitious individual who can work under their own direction towards agreed targets/goals.\\nAbility to manage change and be open to it good time management and an ability to work under stress\\nProven interpersonal skills while contributing to team effort by accomplishing related results as needed\\nMaintain technical knowledge by attending educational workshops, reviewing publications.',\n",
       " 'Roles and Responsibilities\\n\\nIntroduction\\nAs a Data Scientist at IBM, you will help transform our clients’ data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it’s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.\\n\\n\\nYour Role and Responsibilities\\nAs SAS Developer, you are responsible to develop and design analytical solutions and models in SAS\\n\\nYou will develop models along with usage of technologies like SAS e-Miner, base SAS, standard SAS PROCs, advanced SAS etc.\\n\\nDemonstrate expertise in SAS e-Miner tool along with SAS VA\\n\\nProvide programming support of ad-hoc requests and special projects as assigned\\n\\nRequired Technical and Professional Expertise\\nMinimum 10+ years of experience in developing and designing Analytical solutions and models in SAS\\nProficient in developing models and working knowledge of other analytical tools like R/ SPSS is desirable but not mandatory.\\nMinimum of two years of experience of working with SAS e-Miner, base SAS, standard SAS PROCs, advanced SAS etc. and shall demonstrate at least 2 projects where they have worked with SAS e-Miner.\\nExpertise in having worked with SAS VA for at least 2 projects, and with atleast 1 year of experience of working with SAS VA\\nProven communication skills in in English and solid writing, MIS, communication, time management and multi-tasking skills\\n\\nPreferred Technical and Professional Expertise\\nFull time qualification in MCA /M. Tech/B. Tech/B.E./ Post Graduates (Statistics/ Economics/ Mathematics/ Business) and well versed with statistical modelling/ data science concepts\\nYou love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies\\nAmbitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work\\nIntuitive individual with an ability to manage change and proven time management\\nProven interpersonal skills while contributing to team effort by accomplishing related results as needed\\nUp-to-date technical knowledge by attending educational workshops, reviewing publications',\n",
       " 'Job description\\n  Who You Are\\nYou have a broad and deep technical background in data science and analytics and are proficient at analyzing large structured and unstructured datasets to derive insights.\\nYou are highly technical and hands-on but also demonstrate a strong product mindset.\\nYou provide strong technical mentorship to other data scientists and uplevel the overall technical bar of the DS team.\\nYou take responsibility for the group s short-term and long-term strategy, define the teams roadmap, success metrics, and priorities in close collaboration with multi-functional partners.\\nYou drive a culture of trust, respect, and inclusion within your teams.\\nYou are great at\\nDelivering actionable results through your combination of data science solutions, product thinking, statistical knowledge, and deep understanding of data.\\nLead from the front in terms of developing a new hypothesis and connecting observed customer behavior to potential product solutions\\nMastering a fluid, open-ended mandate and possess a 0 to 1 mentality when it comes to crafting solutions\\nCollaborating with product managers, engineers, designers, and user research to drive product impact\\nDistilling complex analytical results into presentable, digestible, and actionable feedback for product and engineering teams\\nLeading and prioritizing projects\\nCreating a culture of rigor and scientific inquiry\\nUnderstanding consumer products\\nQualifications\\nRequirements\\n4+ years experience in data science and quantitative analysis (preferably in an engineering or product role)\\nDemonstrable first principle problem solving skills\\nStrong programming skills (Python, R, SQL) and experience using common analysis tools (Hive, Presto, Scalding)\\nStrong bias to action, creative problem solving mindset, and proactive communication\\nPreferred Qualifications\\nAn advanced degree in a quantitative domain such as Computer Science, Machine Learning, Statistics, Operations Research, or similar. Masters and PhD is a plus but not required\\nProficiency with ML and data analytics technologies such as Spark, Airflow, TensorFlow, etc.\\nPrior work experience with building India focused technology products is a plus.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hre=[]\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in urls:\n",
    "    h=i.get_attribute('href')\n",
    "    hre.append(h)\n",
    "des=[]\n",
    "for a in hre:\n",
    "    driver.get(a)\n",
    "    xt=driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\")    \n",
    "    for j in xt:\n",
    "        tt=j.text\n",
    "        Job_Description.append(tt)    \n",
    "Job_Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Jobs_Title : 20\n",
      "Lenght of Job_Location : 20\n",
      "Lenght of Company_Name : 20\n",
      "Lenght of Job_Description : 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the lists\n",
    "print('Lenght of Jobs_Title :', len(Jobs_Title)), print('Lenght of Job_Location :', len(Job_Location)),\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Job_Description :', len(Job_Description))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jobs_Title of first 10 jobs       \n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "\n",
    "#Job_Location of first 10 jobs\n",
    "Job_Location=Job_Location[0:10]\n",
    "\n",
    "#Company_Name of first 10 jobs\n",
    "Company_Name=Company_Name[0:10]\n",
    "\n",
    "#Job_Description of first 10 jobs\n",
    "Job_Description=Job_Description[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Data Scientist - Data Mining/ Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Job Description :\\n- We are looking for a rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist - Machine/Deep Learni...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Fidius advisory</td>\n",
       "      <td>Working experience in Artificial Intelligence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Atos Syntel Private Limited</td>\n",
       "      <td>Key Responsibilities\\nBe responsible for scali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Roles and Responsibilities\\nSkill : NLP,Semant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMust have strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>Chennai, Pune, Bengaluru</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>We are hiring Data Scientist and Senior Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Role Description:\\nA Sr. Data Scientist who le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>DATA SCIENTIST / MACHINE LEARNING EXPERT\\nGood...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "1  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "2    Data Scientist - Machine Learning (Commerce BU)   \n",
       "3  Principal Data Scientist - Machine/Deep Learni...   \n",
       "4                                     Data Scientist   \n",
       "5     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "6     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "7                       Senior / Lead Data Scientist   \n",
       "8             Senior Data Scientist - NLP/ Python/ R   \n",
       "9  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                          Bengaluru   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "5                                    Pune, Bengaluru   \n",
       "6                                    Pune, Bengaluru   \n",
       "7                           Chennai, Pune, Bengaluru   \n",
       "8                               Bengaluru, Hyderabad   \n",
       "9  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "\n",
       "                        Company Name  \\\n",
       "0       Wrackle Technologies Pvt Ltd   \n",
       "1       Wrackle Technologies Pvt Ltd   \n",
       "2  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "3                    Fidius advisory   \n",
       "4        Atos Syntel Private Limited   \n",
       "5                 Tech Mahindra Ltd.   \n",
       "6                 Tech Mahindra Ltd.   \n",
       "7        TVS CREDIT SERVICES LIMITED   \n",
       "8                 AVI Consulting LLP   \n",
       "9                           CES Ltd.   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Data Scientist - Data Mining/ Machine Learning...  \n",
       "1  Roles and Responsibilities\\nRequirements :\\n\\n...  \n",
       "2  Job Description :\\n- We are looking for a rese...  \n",
       "3  Working experience in Artificial Intelligence,...  \n",
       "4  Key Responsibilities\\nBe responsible for scali...  \n",
       "5  Roles and Responsibilities\\nSkill : NLP,Semant...  \n",
       "6  Roles and Responsibilities\\n\\nMust have strong...  \n",
       "7  We are hiring Data Scientist and Senior Data S...  \n",
       "8  Role Description:\\nA Sr. Data Scientist who le...  \n",
       "9  DATA SCIENTIST / MACHINE LEARNING EXPERT\\nGood...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Analyst jobs (job-title, job-location, company_name, Job_Description)\n",
    "Data_Scientist['Job Title']=Jobs_Title\n",
    "Data_Scientist['Job Location']=Job_Location\n",
    "Data_Scientist['Company Name']=Company_Name\n",
    "Data_Scientist['Job Description']=Job_Description\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityType=25.9.31&ctcFilter=3to6\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Jobs_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for page in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        Jobs_Title.append(i.text)\n",
    "\n",
    "#Job_Location of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        Job_Location.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        Company_Name.append(k.text)\n",
    "\n",
    "#Experience_Required of first 10 jobs data on the website\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        Experience_Required.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Jobs_Title : 20\n",
      "Lenght of Job_Location : 20\n",
      "Lenght of Company_Name : 20\n",
      "Lenght of Experience_Required : 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the lists\n",
    "print('Lenght of Jobs_Title :', len(Jobs_Title)), print('Lenght of Job_Location :', len(Job_Location)),\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Experience_Required :', len(Experience_Required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping first ten elements only       \n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "Job_Location=Job_Location[0:10]\n",
    "Company_Name=Company_Name[0:10]\n",
    "Experience_Required=Experience_Required[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - Computer Vision</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>IRIS SOFTWARE Inc</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>Ciena</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Tableau/Power BI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Talent Stock Solutions</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - IT</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Ehireo</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2            Senior Data Scientist - Computer Vision   \n",
       "3             Data Scientist - Machine Learning/ NLP   \n",
       "4  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "5                                     Data Scientist   \n",
       "6                  Data Scientist - Tableau/Power BI   \n",
       "7  GCP Skilled Analytics Resources (Data engineer...   \n",
       "8                                Data Scientist - IT   \n",
       "9                    Data Scientist Machine Learning   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...   \n",
       "1                                   Gurgaon Gurugram   \n",
       "2                                          Delhi NCR   \n",
       "3                                   Gurgaon Gurugram   \n",
       "4                          Delhi NCR, Noida, Gurgaon   \n",
       "5                                   Gurgaon Gurugram   \n",
       "6                                              Delhi   \n",
       "7                           Pune, Bengaluru, Gurgaon   \n",
       "8                                            Gurgaon   \n",
       "9                                            Gurgaon   \n",
       "\n",
       "                         Company Name Experience Required  \n",
       "0                      Country Veggie             1-3 Yrs  \n",
       "1              IBM India Pvt. Limited             4-8 Yrs  \n",
       "2                   IRIS SOFTWARE Inc             4-9 Yrs  \n",
       "3                              TalPro             2-6 Yrs  \n",
       "4           GABA Consultancy services             0-0 Yrs  \n",
       "5                               Ciena             5-6 Yrs  \n",
       "6              Talent Stock Solutions             1-3 Yrs  \n",
       "7  Aerial Telecom Solutions Pvt. Ltd.             3-8 Yrs  \n",
       "8                              Ehireo             4-9 Yrs  \n",
       "9                           Delhivery             1-3 Yrs  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting all this into a data frame\n",
    "Data_Scientists=pd.DataFrame({})\n",
    "Data_Scientists['Job Title']=Jobs_Title\n",
    "Data_Scientists['Job Location']=Job_Location\n",
    "Data_Scientists['Company Name']=Company_Name\n",
    "Data_Scientists['Experience Required']=Experience_Required\n",
    "Data_Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Company_Name=[]\n",
    "Jobs_Title=[]\n",
    "Job_Posted=[]\n",
    "Company_Rating=[]\n",
    "\n",
    "\n",
    "#Company name of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class=' css-l2wjgv e1n63ojh0 jobLink']\"):\n",
    "        Company_Name.append(i.text)\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='jobInfoItem jobTitle css-13w0lq6 eigr9kq1 jobLink']\"):\n",
    "        Jobs_Title.append(j.text)\n",
    "\n",
    "#Job Posted of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\"):\n",
    "        Job_Posted.append(k.text)\n",
    "\n",
    "#Company rating of first 10 jobs data on the website\n",
    "    for l in driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\"):\n",
    "        Company_Rating.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Company_Name : 1\n",
      "Lenght of Jobs_Title : 0\n",
      "Lenght of Job_Posted : 30\n",
      "Lenght of Company_Rating : 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the lists\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Jobs_Title :', len(Jobs_Title)),\n",
    "print('Lenght of Job_Posted :', len(Job_Posted)), print('Lenght of Company_Rating :', len(Company_Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jobs_Title of first 10 jobs       \n",
    "Company_Name=Company_Name[0:10]\n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "Job_Posted=Job_Posted[0:10]\n",
    "Company_Rating=Company_Rating[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Scientist_Glassdoor=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Data_Scientist_Glassdoor jobs.\n",
    "Data_Scientist_Glassdoor['Company Name']=Company_Name\n",
    "Data_Scientist_Glassdoor['Jobs Title']=Jobs_Title\n",
    "Data_Scientist_Glassdoor['Job Posted']=Job_Posted\n",
    "Data_Scientist_Glassdoor['Company Rating']=Company_Rating\n",
    "Data_Scientist_Glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['₹450K', '₹11,630K'],\n",
       " ['₹420K', '₹1,614K'],\n",
       " ['₹336K', '₹1,010K'],\n",
       " ['₹577K', '₹2,215K'],\n",
       " ['₹587K', '₹2,732K'],\n",
       " ['₹717K', '₹1,575K'],\n",
       " ['₹502K', '₹1,152K'],\n",
       " ['₹621K', '₹1,696K'],\n",
       " ['₹793K', '₹1,264K'],\n",
       " ['₹576K', '₹1,500K']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Company_Name=[]\n",
    "Number_of_salaries=[]\n",
    "Average_Salary=[]\n",
    "Salary=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "        Company_Name.append(i.text)\n",
    "\n",
    "#Number_of_salaries of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "        Number_of_salaries.append(j.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "#Average_Salary of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\"):\n",
    "        Average_Salary.append(k.text.replace('\\r\\n','').replace('\\n',''))\n",
    "        \n",
    "\n",
    "#Min_Salary & Max_Salary of first 10 jobs data on the website\n",
    "Salary_Tags=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']\")\n",
    "for l in Salary_Tags:\n",
    "    salary=l.text\n",
    "    Salary.append(salary.split('\\n'))\n",
    "Salary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Company_Name : 20\n",
      "Lenght of Number_of_salaries : 20\n",
      "Lenght of Average_Salary : 20\n"
     ]
    }
   ],
   "source": [
    "#Length of the lists\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Number_of_salaries :', len(Number_of_salaries)),\n",
    "print('Lenght of Average_Salary :', len(Average_Salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Salary\n",
      "0  [₹450K, ₹11,630K]\n",
      "1   [₹420K, ₹1,614K]\n",
      "2   [₹336K, ₹1,010K]\n",
      "3   [₹577K, ₹2,215K]\n",
      "4   [₹587K, ₹2,732K]\n",
      "5   [₹717K, ₹1,575K]\n",
      "6   [₹502K, ₹1,152K]\n",
      "7   [₹621K, ₹1,696K]\n",
      "8   [₹793K, ₹1,264K]\n",
      "9   [₹576K, ₹1,500K]\n"
     ]
    }
   ],
   "source": [
    "#Creating dataframe for Salary list\n",
    "DF=pd.DataFrame({})\n",
    "DF['Salary']=Salary\n",
    "print(DF.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12,64,182/yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,630K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 7,41,935/yr</td>\n",
       "      <td>₹420K</td>\n",
       "      <td>₹1,614K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 5,99,668/yr</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,010K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 9,94,055/yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,215K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 7,39,040/yr</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹2,732K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 13,37,114/yr</td>\n",
       "      <td>₹717K</td>\n",
       "      <td>₹1,575K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 7,80,374/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,152K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 11,98,792/yr</td>\n",
       "      <td>₹621K</td>\n",
       "      <td>₹1,696K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 10,08,143/yr</td>\n",
       "      <td>₹793K</td>\n",
       "      <td>₹1,264K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 11,34,989/yr</td>\n",
       "      <td>₹576K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Name Number of Salaries  Average Salary  \\\n",
       "0                       Delhivery        13 salaries  ₹ 12,64,182/yr   \n",
       "1              Ericsson-Worldwide        11 salaries   ₹ 7,41,935/yr   \n",
       "2       Tata Consultancy Services        10 salaries   ₹ 5,99,668/yr   \n",
       "3                       Accenture        10 salaries   ₹ 9,94,055/yr   \n",
       "4                             IBM        10 salaries   ₹ 7,39,040/yr   \n",
       "5              UnitedHealth Group         9 salaries  ₹ 13,37,114/yr   \n",
       "6              Valiance Solutions         8 salaries   ₹ 7,80,374/yr   \n",
       "7                      Innovaccer         7 salaries  ₹ 11,98,792/yr   \n",
       "8  Cognizant Technology Solutions         6 salaries  ₹ 10,08,143/yr   \n",
       "9                     EXL Service         6 salaries  ₹ 11,34,989/yr   \n",
       "\n",
       "  Min Salary Max Salary  \n",
       "0      ₹450K   ₹11,630K  \n",
       "1      ₹420K    ₹1,614K  \n",
       "2      ₹336K    ₹1,010K  \n",
       "3      ₹577K    ₹2,215K  \n",
       "4      ₹587K    ₹2,732K  \n",
       "5      ₹717K    ₹1,575K  \n",
       "6      ₹502K    ₹1,152K  \n",
       "7      ₹621K    ₹1,696K  \n",
       "8      ₹793K    ₹1,264K  \n",
       "9      ₹576K    ₹1,500K  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Glassdoor_Salary=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Analyst jobs (job-title, job-location, company_name, experience_required)\n",
    "Glassdoor_Salary['Company Name']=Company_Name\n",
    "Glassdoor_Salary['Number of Salaries']=Number_of_salaries\n",
    "Glassdoor_Salary['Average Salary']=Average_Salary\n",
    "#Creating Columns for Minimum_Salary\n",
    "Glassdoor_Salary['Min Salary']=DF['Salary'].str[:1]\n",
    "Glassdoor_Salary['Min Salary'] = Glassdoor_Salary['Min Salary'].str.get(0)\n",
    "\n",
    "#Creating Columns for Maximum_Salary\n",
    "Glassdoor_Salary['Max Salary']=DF['Salary'].str[1:]\n",
    "Glassdoor_Salary['Max Salary'] = Glassdoor_Salary['Max Salary'].str.get(0)\n",
    "Glassdoor_Salary[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand_Name : 100\n",
      "Product_Description : 100\n",
      "Price : 100\n",
      "Discount : 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Brand_Name=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[]\n",
    "\n",
    "\n",
    "#Brand_Name of the sunglasses\n",
    "for i in range(0, 3):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        Brand_Name.append(i.text)\n",
    "        \n",
    "#Product_Description of the sunglasses\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        if j is not None:\n",
    "            Product_Description.append(j.text)\n",
    "        else:\n",
    "            Product_Description('_')\n",
    "\n",
    "#Price of of the sunglasses\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        Price.append(k.text)\n",
    "\n",
    "#Discount of of the sunglasses\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        Discount.append(k.text)\n",
    "      \n",
    "      \n",
    "  \n",
    "\n",
    " #selecting first 100\n",
    "Brand_Name=Brand_Name[0:100]\n",
    "Product_Description=Product_Description[0:100]\n",
    "Price=Price[0:100]\n",
    "Discount=Discount[0:100]\n",
    "\n",
    "\n",
    "print('Brand_Name :', len(Brand_Name)), print('Product_Description :', len(Product_Description)),\n",
    "print('Price :', len(Price)), print('Discount :', len(Discount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Product_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ayezent</td>\n",
       "      <td>₹212</td>\n",
       "      <td>71% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayezent</td>\n",
       "      <td>₹267</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹596</td>\n",
       "      <td>25% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Deixels</td>\n",
       "      <td>₹189</td>\n",
       "      <td>89% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹195</td>\n",
       "      <td>75% off</td>\n",
       "      <td>UV Protection Oval Sunglasses (56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>₹269</td>\n",
       "      <td>82% off</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (61)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand Name Price Discount  \\\n",
       "0     Ayezent  ₹212  71% off   \n",
       "1     Ayezent  ₹267  86% off   \n",
       "2    Fastrack  ₹596  25% off   \n",
       "3    Fastrack  ₹599  33% off   \n",
       "4    Fastrack  ₹499  37% off   \n",
       "..        ...   ...      ...   \n",
       "95    Deixels  ₹189  89% off   \n",
       "96   Fastrack  ₹599  33% off   \n",
       "97      NuVew  ₹195  75% off   \n",
       "98      Fravy  ₹269  82% off   \n",
       "99  Royal Son  ₹664  66% off   \n",
       "\n",
       "                                  Product_Description  \n",
       "0           UV Protection Rectangular Sunglasses (50)  \n",
       "1          UV Protection Retro Square Sunglasses (52)  \n",
       "2   Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "3        UV Protection Aviator Sunglasses (Free Size)  \n",
       "4   Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "..                                                ...  \n",
       "95              UV Protection Aviator Sunglasses (58)  \n",
       "96  UV Protection, Polarized Wayfarer Sunglasses (56)  \n",
       "97                 UV Protection Oval Sunglasses (56)  \n",
       "98        UV Protection Shield Sunglasses (Free Size)  \n",
       "99              UV Protection Aviator Sunglasses (61)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flipkart_Sunglass=pd.DataFrame({})\n",
    "Flipkart_Sunglass['Brand Name']=Brand_Name\n",
    "Flipkart_Sunglass['Price']=Price\n",
    "Flipkart_Sunglass['Discount']=Discount\n",
    "Flipkart_Sunglass['Product_Description']=Product_Description\n",
    "Flipkart_Sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.7 iphone reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iphone_review(url):\n",
    "    driver = webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    star_rating=[]\n",
    "    short_review=[]\n",
    "    full_review=[]\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        stars=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in stars:\n",
    "            star_rating.append(i.text)\n",
    "        con_reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in con_reviews:\n",
    "            short_review.append(i.text)\n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        j+=1\n",
    "        time.sleep(3)\n",
    "    reviews_iphone=pd.DataFrame({})\n",
    "    reviews_iphone['Stars']=star_rating\n",
    "    reviews_iphone['Short Review']=short_review\n",
    "    reviews_iphone['Detailed Reviews']=full_review\n",
    "    return reviews_iphone\n",
    "    reviews_iphone.to_csv('Iphone_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Detailed Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Well you all know the specifications . One of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars        Short Review  \\\n",
       "0      5    Perfect product!   \n",
       "1      5       Great product   \n",
       "2      5  Highly recommended   \n",
       "3      5    Perfect product!   \n",
       "4      5           Brilliant   \n",
       "..   ...                 ...   \n",
       "95     5           Brilliant   \n",
       "96     5   Worth every penny   \n",
       "97     5           Wonderful   \n",
       "98     5       Great product   \n",
       "99     5  Highly recommended   \n",
       "\n",
       "                                     Detailed Reviews  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "..                                                ...  \n",
       "95  I have migrated from OP 7pro... and trust me, ...  \n",
       "96  Previously I was using one plus 3t it was a gr...  \n",
       "97  This is my first ever I phone. Before this I w...  \n",
       "98  Well you all know the specifications . One of ...  \n",
       "99  It's my first time to use iOS phone and I am l...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. no 8 Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneakers(url):\n",
    "    driver = webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    brand_name=[]\n",
    "    prod_desc=[]\n",
    "    prod_price=[]\n",
    "    prod_disc=[]\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            brand_name.append(brand.text)\n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            prod_desc.append(description.text)\n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            prod_price.append(price.text)\n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            prod_disc.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "    sneakers=pd.DataFrame({})\n",
    "    sneakers['Brand']=brand_name[:100]\n",
    "    sneakers['Prod_Desc']=prod_desc[:100]\n",
    "    sneakers['Prod_Price']=prod_price[:100]\n",
    "    sneakers['Prod_Disc']=prod_disc[:100]\n",
    "    return sneakers\n",
    "    sneakers.to_csv('sneakers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Prod_Desc</th>\n",
       "      <th>Prod_Price</th>\n",
       "      <th>Prod_Disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kizaar</td>\n",
       "      <td>Fashionable Casual, Canvas,official or Partywe...</td>\n",
       "      <td>₹471</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "      <td>₹235</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Chevit Trendy Fashion Sports Combo Pack of 3 P...</td>\n",
       "      <td>₹597</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>SUMMITS - BRISBANE Sneakers For Men</td>\n",
       "      <td>₹2,579</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹451</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Absolute comfort</td>\n",
       "      <td>EVAW2 Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Ontario IDP Sneakers For Men</td>\n",
       "      <td>₹1,047</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                          Prod_Desc  \\\n",
       "0             Kizaar  Fashionable Casual, Canvas,official or Partywe...   \n",
       "1           Longwalk                         Men Boxer Sneakers For Men   \n",
       "2             Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3             Chevit  Chevit Trendy Fashion Sports Combo Pack of 3 P...   \n",
       "4       Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "..               ...                                                ...   \n",
       "95          Skechers                SUMMITS - BRISBANE Sneakers For Men   \n",
       "96      Robbie jones                                   Sneakers For Men   \n",
       "97  Absolute comfort                             EVAW2 Sneakers For Men   \n",
       "98              Puma                       Ontario IDP Sneakers For Men   \n",
       "99            Chevit  Smart Casuals Canvas Shoes Combo pack of 2 Sne...   \n",
       "\n",
       "   Prod_Price Prod_Disc  \n",
       "0        ₹471   52% off  \n",
       "1        ₹235   52% off  \n",
       "2        ₹474   76% off  \n",
       "3        ₹597   66% off  \n",
       "4        ₹399   60% off  \n",
       "..        ...       ...  \n",
       "95     ₹2,579   54% off  \n",
       "96       ₹451   60% off  \n",
       "97       ₹199   65% off  \n",
       "98     ₹1,047   70% off  \n",
       "99       ₹299    5% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.no.9 Myntra shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra_shoes(url):\n",
    "    driver = webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    brand_name=[]\n",
    "    description=[]\n",
    "    prod_price=[]\n",
    "    driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    j=0\n",
    "    while j<2:\n",
    "        time.sleep(5)\n",
    "        brands=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "        for brand in brands:\n",
    "            brand_name.append(brand.text)\n",
    "        descs=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "        for desc in descs:\n",
    "            description.append(desc.text)\n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "        for price in prices:\n",
    "                prod_price.append(price.text)\n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()    \n",
    "        \n",
    "        j+=1\n",
    "    myntra=pd.DataFrame({})\n",
    "    myntra['Brand']=brand_name\n",
    "    myntra['Prod_Desc']=description\n",
    "    myntra['Prod_Price']=prod_price\n",
    "    return myntra\n",
    "    myntra.to_csv('Myntra_shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Prod_Desc</th>\n",
       "      <th>Prod_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men DEERUPT RUNNER Sneakers</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 8799Rs. 10999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men HYBRID NETFIT Running Shoe</td>\n",
       "      <td>Rs. 6599Rs. 10999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>Rs. 7996Rs. 9995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Solid SKYVE MAX Sneakers</td>\n",
       "      <td>Rs. 7436Rs. 9295(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 6204Rs. 7299(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Mega Flexagon Training Shoes</td>\n",
       "      <td>Rs. 6159Rs. 7999(23% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Formal Genuine Leather Derbys</td>\n",
       "      <td>Rs. 6153Rs. 8790(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Air Mega Running Shoes</td>\n",
       "      <td>Rs. 5354Rs. 6299(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Women Flexagon Training Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Prod_Desc  \\\n",
       "0   ADIDAS Originals              Men DEERUPT RUNNER Sneakers   \n",
       "1          Cole Haan                   Women Leather Sneakers   \n",
       "2               Puma           Men HYBRID NETFIT Running Shoe   \n",
       "3               Nike            PEGASUS FLYEASE Running Shoes   \n",
       "4               Nike             Men Solid SKYVE MAX Sneakers   \n",
       "..               ...                                      ...   \n",
       "95              Xtep                        Men Running Shoes   \n",
       "96            Reebok             Mega Flexagon Training Shoes   \n",
       "97      Kenneth Cole  Men Solid Formal Genuine Leather Derbys   \n",
       "98              Xtep               Men Air Mega Running Shoes   \n",
       "99            Reebok            Women Flexagon Training Shoes   \n",
       "\n",
       "                    Prod_Price  \n",
       "0    Rs. 7199Rs. 8999(20% OFF)  \n",
       "1   Rs. 8799Rs. 10999(20% OFF)  \n",
       "2   Rs. 6599Rs. 10999(40% OFF)  \n",
       "3    Rs. 7996Rs. 9995(20% OFF)  \n",
       "4    Rs. 7436Rs. 9295(20% OFF)  \n",
       "..                         ...  \n",
       "95   Rs. 6204Rs. 7299(15% OFF)  \n",
       "96   Rs. 6159Rs. 7999(23% OFF)  \n",
       "97   Rs. 6153Rs. 8790(30% OFF)  \n",
       "98   Rs. 5354Rs. 6299(15% OFF)  \n",
       "99                    Rs. 7999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myntra_shoes('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.no 10 Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laptop_info(url):\n",
    "    driver = webdriver.Chrome('D:\\chromedriver_win32\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    Title=[]\n",
    "    Price=[]\n",
    "    Rating=[]\n",
    "    driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "    driver.find_element_by_xpath('//input[@type=\"submit\"]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a').click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()\n",
    "    titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for title in titles:\n",
    "        Title.append(title.text)\n",
    "    prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "    for price in prices:\n",
    "        Price.append(price.text)\n",
    "\n",
    "    ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "    for rating in ratings:\n",
    "        Rating.append(rating.get_attribute('aria-label'))\n",
    "    laptops=pd.DataFrame({})\n",
    "    laptops['Title']=Title[:11]\n",
    "    laptops['Price']=Price[:11]\n",
    "    laptops['Rating']=Rating[:11]\n",
    "    return laptops\n",
    "    laptops.to_csv('Laptops_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP 15 Intel Pentium Gold 6405U Processor Entry...</td>\n",
       "      <td>26,791</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire 5 14\" Full HD IPS Display Thin and...</td>\n",
       "      <td>59,990</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 3i Intel Celeron N4020 15....</td>\n",
       "      <td>22,990</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15 Intel Pentium Gold 6405U Processor Entry...</td>\n",
       "      <td>26,791</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 AMD Athlon Silver 3050U ...</td>\n",
       "      <td>25,990</td>\n",
       "      <td>2.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP 15 db1069AU 15.6-inch Laptop (3rd Gen Ryzen...</td>\n",
       "      <td>67,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Ideapad Slim 3 AMD Ryzen 3 15.6 inch Fu...</td>\n",
       "      <td>40,999</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVITA PURA NS14A6INU442-SGGYB 14-inch Laptop (...</td>\n",
       "      <td></td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop 3340 Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AVITA PURA NS14A6INU442-MEGYB 14-inch Laptop (...</td>\n",
       "      <td></td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mi Notebook 14 Intel Core i5-10210U 10th Gen T...</td>\n",
       "      <td>30,160</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title   Price  \\\n",
       "0   HP 15 Intel Pentium Gold 6405U Processor Entry...  26,791   \n",
       "1   Acer Aspire 5 14\" Full HD IPS Display Thin and...  59,990   \n",
       "2   Lenovo IdeaPad Slim 3i Intel Celeron N4020 15....  22,990   \n",
       "3   HP 15 Intel Pentium Gold 6405U Processor Entry...  26,791   \n",
       "4   Lenovo IdeaPad Slim 3 AMD Athlon Silver 3050U ...  25,990   \n",
       "5   HP 15 db1069AU 15.6-inch Laptop (3rd Gen Ryzen...  67,990   \n",
       "6   Lenovo Ideapad Slim 3 AMD Ryzen 3 15.6 inch Fu...  40,999   \n",
       "7   AVITA PURA NS14A6INU442-SGGYB 14-inch Laptop (...           \n",
       "8   (Renewed) Dell Latitude Laptop 3340 Intel Core...           \n",
       "9   AVITA PURA NS14A6INU442-MEGYB 14-inch Laptop (...           \n",
       "10  Mi Notebook 14 Intel Core i5-10210U 10th Gen T...  30,160   \n",
       "\n",
       "                Rating  \n",
       "0   4.1 out of 5 stars  \n",
       "1   3.4 out of 5 stars  \n",
       "2   3.0 out of 5 stars  \n",
       "3   4.1 out of 5 stars  \n",
       "4   2.0 out of 5 stars  \n",
       "5   4.3 out of 5 stars  \n",
       "6   4.0 out of 5 stars  \n",
       "7   3.9 out of 5 stars  \n",
       "8   4.1 out of 5 stars  \n",
       "9   4.3 out of 5 stars  \n",
       "10  3.4 out of 5 stars  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_info('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
